{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctionnalités avancées d'Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    history = history or []\n",
    "    if message.startswith(\"How many\"):\n",
    "        response = random.randint(1, 10)\n",
    "    elif message.startswith(\"How\"):\n",
    "        response = random.choice([\"Great\", \"Good\", \"Okay\", \"Bad\"])\n",
    "    elif message.startswith(\"Where\"):\n",
    "        response = random.choice([\"Here\", \"There\", \"Somewhere\"])\n",
    "    else:\n",
    "        response = \"I don't know\"\n",
    "    history.append((message, response))\n",
    "    return history, history\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    chat,\n",
    "    [\"text\", \"state\"],\n",
    "    [\"chatbot\", \"state\"],\n",
    "    allow_screenshot=False,\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "inception_net = tf.keras.applications.MobileNetV2()  # charger le modèle\n",
    "\n",
    "# Télécharger des étiquettes lisibles par l'homme pour ImageNet\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "\n",
    "def classify_image(inp):\n",
    "    inp = inp.reshape((-1, 224, 224, 3))\n",
    "    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    prediction = inception_net.predict(inp).flatten()\n",
    "    return {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "\n",
    "\n",
    "image = gr.Image(shape=(224, 224))\n",
    "label = gr.Label(num_top_classes=3)\n",
    "\n",
    "title = \"Gradio Image Classifiction + Interpretation Example\"\n",
    "gr.Interface(\n",
    "    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\", title=title\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "inception_net = tf.keras.applications.MobileNetV2()  # charger le modèle\n",
    "\n",
    "# Télécharger des étiquettes lisibles par l'homme pour ImageNet\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "\n",
    "def classify_image(inp):\n",
    "    inp = inp.reshape((-1, 224, 224, 3))\n",
    "    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    prediction = inception_net.predict(inp).flatten()\n",
    "    return {labels[i]: float(prediction[i]) for i in range(1000)}\n",
    "\n",
    "\n",
    "image = gr.Image(shape=(224, 224))\n",
    "label = gr.Label(num_top_classes=3)\n",
    "\n",
    "title = \"Gradio Image Classifiction + Interpretation Example\"\n",
    "gr.Interface(\n",
    "    fn=classify_image, inputs=image, outputs=label, interpretation=\"default\", title=title\n",
    ").launch(auth=(\"admin\", \"pass1234\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fonctionnalités avancées d'Interface",
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
