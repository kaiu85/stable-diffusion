{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "in-painting with stable diffusion using ðŸ§¨diffusers",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiu85/stable-diffusion/blob/main/diffusers/in_painting_with_stable_diffusion_using_diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-painting pipeline for Stable Diffusion using ðŸ§¨ Diffusers \n",
        "\n",
        "This notebook shows how to do text-guided in-painting with Stable Diffusion model using  ðŸ¤— Hugging Face [ðŸ§¨ Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "For a general introduction to the Stable Diffusion model please refer to this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb)."
      ],
      "metadata": {
        "id": "aukP90uZv60A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khoCNOCuHNd"
      },
      "outputs": [],
      "source": [
        "!pip install -qq -U diffusers==0.6.0 transformers ftfy gradio\n",
        "!pip install git+https://github.com/huggingface/diffusers.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First , in order to use the model, you need to accept the model license before downloading or using the weights. In this post we'll use `runwayml/stable-diffusion-inpainting` model released by Runwayml so you'll need to  visit [its card](https://huggingface.co/runwayml/stable-diffusion-inpainting), read the license and tick the checkbox if you agree. \n",
        "\n",
        "You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work. For more information on access tokens, please refer to [this section of the documentation](https://huggingface.co/docs/hub/security-tokens)."
      ],
      "metadata": {
        "id": "qHlMV5SwwDbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "mgCBtC7luTmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import PIL\n",
        "import gradio as gr\n",
        "from diffusers import StableDiffusionInpaintPipeline"
      ],
      "metadata": {
        "id": "dxKnZonKuYgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_path = \"runwayml/stable-diffusion-inpainting\"\n",
        "\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    model_path,\n",
        "    revision=\"fp16\", \n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=True\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "MfUEmooNuyKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = PIL.Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
        "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\""
      ],
      "metadata": {
        "id": "hvdHYdtTu6KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = download_image(img_url).resize((512, 512))\n",
        "image"
      ],
      "metadata": {
        "id": "y4OVr7pPvMWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_image = download_image(mask_url).resize((512, 512))\n",
        "mask_image"
      ],
      "metadata": {
        "id": "GSdamba-vo0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a tucan sitting on a bench\"\n",
        "\n",
        "guidance_scale=7.5\n",
        "num_samples = 3\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(0) # change the seed to get different results\n",
        "\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    image=image,\n",
        "    mask_image=mask_image,\n",
        "    guidance_scale=guidance_scale,\n",
        "    generator=generator,\n",
        "    num_images_per_prompt=num_samples,\n",
        ").images"
      ],
      "metadata": {
        "id": "OkePC-DGvyz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insert initial image in the list so we can compare side by side\n",
        "images.insert(0, image)"
      ],
      "metadata": {
        "id": "WtfJyo1XhBP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_grid(images, 1, num_samples + 1)"
      ],
      "metadata": {
        "id": "loXzMOIxv9OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio Demo"
      ],
      "metadata": {
        "id": "ZupJ7HzIzRQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dict, prompt):\n",
        "  image =  dict['image'].convert(\"RGB\").resize((512, 512))\n",
        "  mask_image = dict['mask'].convert(\"RGB\").resize((512, 512))\n",
        "  images = pipe(prompt=prompt, image=image, mask_image=mask_image).images\n",
        "  return(images[0])"
      ],
      "metadata": {
        "id": "byoa1q2zyd6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(\n",
        "    predict,\n",
        "    title = 'Stable Diffusion In-Painting',\n",
        "    inputs=[\n",
        "        gr.Image(source = 'upload', tool = 'sketch', type = 'pil'),\n",
        "        gr.Textbox(label = 'prompt')\n",
        "    ],\n",
        "    outputs = [\n",
        "        gr.Image()\n",
        "        ]\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "id": "R596bpT2ynqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "12tBuctiypw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}